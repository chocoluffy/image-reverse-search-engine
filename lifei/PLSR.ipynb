{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_decomposition import PLSRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_concat_train = np.load('./features/descriptions_train_concat_embed_vectors.npy')\n",
    "des_concat_test = np.load('./features/descriptions_test_concat_embed_vectors.npy')\n",
    "des_long_train = np.load('./features/descriptions_train_long_embed_vectors.npy')\n",
    "des_long_test = np.load('./features/descriptions_test_long_embed_vectors.npy')\n",
    "image_1000_train = np.load('./features/image_features_1000_train.npy')\n",
    "image_1000_test = np.load('./features/image_features_1000_test.npy')\n",
    "image_2048_train = np.load('./features/image_features_2048_train.npy')\n",
    "image_2048_test = np.load('./features/image_features_2048_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_20(vec, vec_set):\n",
    "    dis = [np.linalg.norm(np.array(vec) - np.array(x)) for x in vec_set]\n",
    "    return np.argsort(dis)[:20]\n",
    "\n",
    "def map20score(y, pred):\n",
    "    if y in pred:\n",
    "        return (20 - pred.tolist().index(y)) / 20.0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def map20eval(pls, des_vectors, image_vectors):\n",
    "    image_pred = pls.predict(des_vectors)\n",
    "    top_20 = [get_nearest_20(vec, image_vectors) for vec in image_pred]\n",
    "    print(len(top_20))\n",
    "    scores = [map20score(i, top_20[i]) for i in range(len(top_20))]\n",
    "    print \"score: %f\" % np.mean(scores)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/sklearn/cross_decomposition/pls_.py:77: UserWarning: Maximum number of iterations reached\n",
      "  warnings.warn('Maximum number of iterations reached')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PLSRegression(copy=True, max_iter=500, n_components=256, scale=True,\n",
       "       tol=1e-06)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pls_concat_1000 = PLSRegression(n_components=256)\n",
    "pls_concat_1000.fit(des_concat_train, image_1000_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_concat_1000 = pls_concat_1000.predict(des_concat_test)\n",
    "top_20_concat_1000 = [get_nearest_20(vec, image_1000_test) for vec in pred_concat_1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_submission(top_20, output_path):\n",
    "    top_20_image_IDs = map(lambda x: ' '.join(map(lambda xx: str(xx) + '.jpg', x)), top_20)\n",
    "    description_ID = map(lambda x: str(x) + '.txt', range(len(top_20)))\n",
    "    submission_df = pd.DataFrame({'Descritpion_ID': description_ID, 'Top_20_Image_IDs': top_20_image_IDs})\n",
    "    submission_df.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_submission(top_20_concat_1000, 'submissions/PLSR_256_concat_1000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PLSRegression(copy=True, max_iter=1000, n_components=256, scale=True,\n",
       "       tol=1e-06)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pls_concat_1000 = PLSRegression(n_components=256, max_iter=1000)\n",
    "pls_concat_1000.fit(des_concat_train, image_1000_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_concat_1000 = pls_concat_1000.predict(des_concat_test)\n",
    "top_20_concat_1000 = [get_nearest_20(vec, image_1000_test) for vec in pred_concat_1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_submission(top_20_concat_1000, 'submissions/PLSR_256_concat_1000_1000iter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
